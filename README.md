# ForesightSafety-Bench

<p align="center">
  <a href="README_CN.md">ä¸­æ–‡</a> | English
</p>

**ForesightSafety-Bench** is a comprehensive benchmark for evaluating the safety of large language models (LLMs) across multiple risk dimensions, including basic content safety, deception, embodied AI, industrial safety, and existential risks.

ğŸ† **ForesightSafety-Bench Leaderboard**: Explore our comprehensive LLM safety evaluation results at [ForesightSafety-Bench Leaderboard](https://foresightsafety-bench.beijing-aisi.ac.cn/) ğŸ“Š

![ForesightSafety-Bench Framework](assets/framework.png)
*ForesightSafety-Bench framework architecture demonstrates the end-to-end process of LLM safety evaluation across multiple risk dimensions.*

## Overall Results

![Overall Results](assets/overall_bar.jpg)

## Dependencies

This benchmark relies on [PandaGuard](https://github.com/Beijing-AISI/panda-guard) for attack, defense, and evaluation algorithms. Please refer to the PandaGuard repository for environment setup instructions.

### Quick Start

```bash
# Clone this repository
git clone https://github.com/Beijing-AISI/ForesightSafety-Bench.git
cd ForesightSafety-Bench

# Install PandaGuard
pip install git+https://github.com/Beijing-AISI/panda-guard.git
```

For detailed installation and configuration, please visit the [PandaGuard documentation](https://github.com/Beijing-AISI/panda-guard).

## Project Structure

```
ForesightSafety-Bench/
â”œâ”€â”€ assets/                      # Visual assets
â”‚   â”œâ”€â”€ framework.png            # Framework architecture diagram
â”‚   â””â”€â”€ overall_bar.jpg          # Overall results visualization
â”œâ”€â”€ Fundamental-Safety/          # Fundamental content safety evaluation
â”‚   â””â”€â”€ base.csv                 # Basic safety test dataset
â”œâ”€â”€ Social-AI-Safety/            # Social AI safety and deception evaluation
â”‚   â”œâ”€â”€ configs/                 # Configuration files for LLMs and datasets
â”‚   â”œâ”€â”€ data/                    # Social AI safety test datasets
â”‚   â”œâ”€â”€ src/                     # Source code
â”‚   â”œâ”€â”€ analysis.py              # Analysis script
â”‚   â”œâ”€â”€ batch_judge.py           # Batch judgment script
â”‚   â””â”€â”€ batch_run.py             # Batch execution script
â”œâ”€â”€ Embodied-AI-Safety/          # Embodied AI safety evaluation
â”‚   â”œâ”€â”€ merged_goals_classified.csv  # Classified goals dataset
â”‚   â””â”€â”€ src/                     # Source code and PandaGuard integration
â”œâ”€â”€ Industrial-Safety/           # Industrial safety evaluation
â”‚   â””â”€â”€ industrial.csv           # Industrial safety dataset
â”œâ”€â”€ Environmental-Safety/        # Environmental safety evaluation
â”‚   â”œâ”€â”€ code/                    # Evaluation scripts
â”‚   â””â”€â”€ dataset/                 # Environmental safety datasets
â””â”€â”€ Catastrophic-and-Existential-Risks/  # Catastrophic and existential risk evaluation
    â”œâ”€â”€ code/                    # Test code for various risk scenarios
    â”‚   â”œâ”€â”€ 3spec/               # Three-specification evaluation
    â”‚   â””â”€â”€ 4spec/               # Four-specification evaluation
    â””â”€â”€ dataset/                 # Risk assessment datasets
```

## Citation

If you find ForesightSafety-Bench useful for your research, please cite our work:

```bibtex
@misc{tong2026foresightsafetybenchfrontierrisk,
      title={ForesightSafety Bench: A Frontier Risk Evaluation and Governance Framework towards Safe AI}, 
      author={Haibo Tong and Feifei Zhao and Linghao Feng and Ruoyu Wu and Ruolin Chen and Lu Jia and Zhou Zhao and Jindong Li and Tenglong Li and Erliang Lin and Shuai Yang and Enmeng Lu and Yinqian Sun and Qian Zhang and Zizhe Ruan and Zeyang Yue and Ping Wu and Huangrui Li and Chengyi Sun and Yi Zeng},
      year={2026},
      eprint={2602.14135},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2602.14135}, 
}
```

## Contact

- **Website**: [https://foresightsafety-bench.beijing-aisi.ac.cn/](https://foresightsafety-bench.beijing-aisi.ac.cn/)
- **Organization**: Beijing Institute of AI Safety and Governance (Beijing-AISI)
- **Email**: contact@beijing-aisi.ac.cn

## License

This project is licensed under the MIT License - see the LICENSE file for details.
